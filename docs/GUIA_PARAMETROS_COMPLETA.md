# üìñ KI Platform - Gu√≠a Completa de Par√°metros

## √çndice

1. [Tab 1: Dataset Manager](#tab-1-dataset-manager)
2. [Tab 2: Dataset Review](#tab-2-dataset-review)
3. [Tab 3: Training Manager](#tab-3-training-manager)
4. [Tab 4: Testing System](#tab-4-testing-system)
5. [Tab 5: Settings](#tab-5-settings)
6. [CLI Tool: dataset_cli.py](#cli-tool-dataset_clipy)
7. [Archivos de Configuraci√≥n](#archivos-de-configuraci√≥n)

---

# Tab 1: Dataset Manager

## üì§ Upload Documents

### **File Upload**
- **Tipo:** File uploader (drag & drop)
- **Formatos soportados:**
  - `.pdf` - Documentos PDF
  - `.docx` - Microsoft Word
  - `.txt` / `.text` - Texto plano
  - `.md` / `.markdown` - Markdown
  - `.log` - Archivos log
- **M√∫ltiples archivos:** S√≠
- **L√≠mite de tama√±o:** Sin l√≠mite espec√≠fico (depende de memoria)
- **Uso:** Arrastra archivos o haz click para seleccionar

**Ejemplo:**
```
Upload 10 PDFs sobre SSRF vulnerability reports
‚Üí Archivos se muestran en tabla con:
  - Name: nombre del archivo
  - Size: tama√±o en KB
  - Type: PDF/DOCX/TXT
  - Status: ‚úÖ Supported / ‚ùå Unsupported
```

---

## ‚öôÔ∏è Dataset Configuration

### **Vulnerability Category**
- **Tipo:** Dropdown
- **Valores:**
  - `SSRF` - Server-Side Request Forgery
  - `XSS` - Cross-Site Scripting
  - `SQLi` - SQL Injection
  - `IDOR` - Insecure Direct Object Reference
  - `RCE` - Remote Code Execution
  - `XXE` - XML External Entity
  - `CSRF` - Cross-Site Request Forgery
  - `LFI/RFI` - Local/Remote File Inclusion
  - `Authentication Bypass` - Bypass de autenticaci√≥n
  - `Custom` - Categor√≠a personalizada
- **Default:** `SSRF`
- **Uso:** Selecciona el tipo de vulnerabilidad de tus documentos

**Qu√© hace:**
- Define la categor√≠a de los ejemplos generados
- Influye en los prompts usados para generaci√≥n con Ollama
- Organiza los datasets por tipo de vulnerabilidad

**Ejemplo:**
```
Category: SSRF
‚Üí Ollama genera ejemplos espec√≠ficos de SSRF
‚Üí Dataset guardado con metadata: {"category": "SSRF"}
```

---

### **Examples per Document**
- **Tipo:** Slider
- **Rango:** 1 - 20
- **Default:** 5
- **Paso:** 1
- **Uso:** N√∫mero de ejemplos de entrenamiento a generar por cada documento

**Qu√© hace:**
- Controla cu√°ntos ejemplos se extraen de cada documento
- M√°s ejemplos = dataset m√°s grande, pero puede tener redundancia
- Menos ejemplos = dataset m√°s peque√±o, pero m√°s conciso

**Recomendaciones:**
- **Documentos cortos (< 1000 palabras):** 3-5 ejemplos
- **Documentos medianos (1000-3000 palabras):** 5-10 ejemplos
- **Documentos largos (> 3000 palabras):** 10-15 ejemplos

**Ejemplo:**
```
10 documentos √ó 5 ejemplos/doc = 50 ejemplos totales
‚Üí Si subes 10 PDFs y configuras 5 ejemplos
‚Üí Resultado: dataset con ~50 ejemplos
```

---

### **Quality Threshold**
- **Tipo:** Dropdown
- **Valores:**
  - `High` - Alta calidad (score m√≠nimo: 0.7)
  - `Medium` - Calidad media (score m√≠nimo: 0.5)
  - `Low` - Baja calidad (score m√≠nimo: 0.3)
- **Default:** `High`
- **Uso:** Define el umbral m√≠nimo de calidad aceptable

**Qu√© hace:**
- Filtra autom√°ticamente ejemplos de baja calidad
- Ejemplos con score inferior al threshold son rechazados
- Afecta la tasa de rechazo durante generaci√≥n

**C√°lculo de Quality Score:**
```python
score = 0.0

# Required fields (30%)
if tiene instruction + input + output:
    score += 0.3

# Output length (30%)
if output > 200 caracteres:
    score += 0.3
elif output > 100 caracteres:
    score += 0.15

# Instruction clarity (20%)
if 20 < len(instruction) < 200:
    score += 0.2

# Input context (20%)
if len(input) > 20:
    score += 0.2

total_score = min(score, 1.0)
```

**Ejemplo:**
```
Quality: High (threshold 0.7)
‚Üí Genera 50 ejemplos
‚Üí 45 tienen score >= 0.7 (validados)
‚Üí 5 tienen score < 0.7 (rechazados)
‚Üí Dataset final: 45 ejemplos
‚Üí Tasa de rechazo: 10%
```

---

### **Dataset Name**
- **Tipo:** Text input
- **Default:** `my_dataset`
- **Caracteres permitidos:** Alfanum√©ricos, guiones, guiones bajos, espacios
- **Uso:** Nombre para guardar el dataset

**Qu√© hace:**
- Define el nombre del archivo JSON
- Sanitiza caracteres especiales autom√°ticamente
- Agrega extensi√≥n `.json` autom√°ticamente

**Convenciones recomendadas:**
```
ssrf_v1             ‚Üí Primera versi√≥n de dataset SSRF
ssrf_raw_v1         ‚Üí Dataset sin revisar
ssrf_reviewed_v1    ‚Üí Dataset revisado manualmente
ssrf_final          ‚Üí Dataset final listo para entrenar
xss_writeups        ‚Üí XSS desde writeups
sqli_merged         ‚Üí SQLi mergeado de varias fuentes
```

**Ejemplo:**
```
Dataset Name: ssrf_hackerone_v1
‚Üí Guarda en: storage/datasets/ssrf_hackerone_v1.json
```

---

## üéØ Action Buttons

### **üìÑ Parse Documents**
- **Acci√≥n:** Parsea los documentos subidos
- **Requiere:** Archivos subidos
- **Proceso:**
  1. Lee cada archivo soportado
  2. Extrae texto completo
  3. Cuenta palabras
  4. Muestra resultados en tabla

**Output:**
```
Parsing Results:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ File            ‚îÇ Type ‚îÇ Words  ‚îÇ Status    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ssrf_report.pdf ‚îÇ PDF  ‚îÇ 2,345  ‚îÇ ‚úÖ Success‚îÇ
‚îÇ xxe_guide.docx  ‚îÇ DOCX ‚îÇ 1,890  ‚îÇ ‚úÖ Success‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Status: ‚úÖ Parsed 2 documents (4,235 total words)
```

---

### **üéØ Generate Dataset**
- **Acci√≥n:** Genera ejemplos de entrenamiento usando Ollama
- **Requiere:** Documentos parseados
- **Proceso:**
  1. Verifica si Ollama est√° disponible
  2. Por cada documento:
     - Crea prompt con contexto del documento
     - Llama a Ollama (Llama 3.1)
     - Genera N ejemplos
     - Valida calidad de cada ejemplo
     - Rechaza ejemplos con score bajo
  3. Compila estad√≠sticas
  4. Retorna dataset completo

**Generation Log (ejemplo):**
```
[INFO] Starting dataset generation with Ollama
[INFO] Category: SSRF
[INFO] Target: 5 examples per document
[INFO] Quality level: High
[INFO] Total documents: 10

[‚úì] Ollama is running - using real AI generation

[SUCCESS] Dataset generation complete!

üìä Statistics:
  ‚Ä¢ Documents processed: 10
  ‚Ä¢ Examples generated: 50
  ‚Ä¢ Examples validated: 45
  ‚Ä¢ Examples rejected: 5

[INFO] Quality rejection rate: 10.0%
```

**Si Ollama NO est√° disponible:**
```
[!] Ollama not available - using simulated generation
[!] Install Ollama and run 'ollama serve' for real generation
```

---

### **üíæ Save Dataset**
- **Acci√≥n:** Guarda el dataset generado
- **Requiere:** Dataset generado
- **Formato:** JSON
- **Ubicaci√≥n:** `storage/datasets/`

**Estructura del archivo JSON:**
```json
{
  "metadata": {
    "name": "ssrf_v1",
    "created_at": "2025-10-02T19:30:00",
    "category": "SSRF",
    "total_examples": 45,
    "quality_level": "High",
    "stats": {
      "total_documents": 10,
      "total_generated": 50,
      "total_validated": 45,
      "total_rejected": 5
    }
  },
  "examples": [
    {
      "instruction": "Explica c√≥mo detectar SSRF en APIs",
      "input": "Tengo una API que permite URLs en par√°metros",
      "output": "Para detectar SSRF en APIs...",
      "category": "SSRF",
      "quality_score": 0.85,
      "source_document": "ssrf_report.pdf"
    }
    // ... m√°s ejemplos
  ]
}
```

---

# Tab 2: Dataset Review

## üìÇ Load Dataset

### **Select Dataset**
- **Tipo:** Dropdown
- **Valores:** Todos los datasets en `storage/datasets/*.json`
- **Actualizaci√≥n:** Click en "üîÑ Refresh List"
- **Uso:** Selecciona dataset a revisar

**Ejemplo:**
```
Datasets disponibles:
- ssrf_v1.json
- ssrf_raw_v2.json
- xss_writeups.json
- sqli_merged.json
```

---

### **üìÇ Load Dataset Button**
- **Acci√≥n:** Carga el dataset seleccionado
- **Proceso:**
  1. Lee archivo JSON
  2. Valida estructura
  3. Carga primer ejemplo
  4. Actualiza contador (1/50)

**Output:**
```
Status: Example 1/50 | Category: SSRF | Quality: 0.85 | Status: ‚úÖ Good
```

---

## üîç Navigate Examples

### **‚¨ÖÔ∏è Previous / ‚û°Ô∏è Next**
- **Tipo:** Botones
- **Acci√≥n:** Navega al ejemplo anterior/siguiente
- **L√≠mites:** Se detiene en primer/√∫ltimo ejemplo

---

### **Position Indicator**
- **Tipo:** Text (read-only)
- **Formato:** `N/TOTAL` (ej: `5/50`)
- **Muestra:** Posici√≥n actual en el dataset

---

### **Jump to Example Slider**
- **Tipo:** Slider
- **Rango:** 0 - (total_examples - 1)
- **Uso:** Salta directamente a cualquier ejemplo
- **Actualizaci√≥n:** Al mover slider, carga ese ejemplo

---

## ‚úèÔ∏è Edit Example

### **Instruction**
- **Tipo:** Text area (3 l√≠neas)
- **Contenido:** La tarea o pregunta del ejemplo
- **Editable:** S√≠
- **Uso:** Modifica la instrucci√≥n si est√° mal redactada

**Ejemplo:**
```
Antes: "dime como hacer ssrf"
Despu√©s: "Explica c√≥mo identificar vulnerabilidades SSRF en AWS Lambda"
```

---

### **Input**
- **Tipo:** Text area (4 l√≠neas)
- **Contenido:** Contexto de entrada para la tarea
- **Editable:** S√≠
- **Uso:** Modifica el contexto de entrada

**Ejemplo:**
```
Antes: "tengo una funci√≥n lambda"
Despu√©s: "Tengo una funci√≥n AWS Lambda que hace peticiones HTTP a URLs proporcionadas por usuarios"
```

---

### **Output**
- **Tipo:** Text area (8 l√≠neas)
- **Contenido:** Respuesta esperada del modelo
- **Editable:** S√≠
- **Uso:** Corrige o mejora la respuesta esperada

**Ejemplo:**
```
Antes: "SSRF es malo"
Despu√©s: "SSRF (Server-Side Request Forgery) permite a un atacante...
[explicaci√≥n t√©cnica detallada de 200+ palabras]"
```

---

### **Quality Score**
- **Tipo:** Slider
- **Rango:** 0.0 - 1.0
- **Paso:** 0.01
- **Default:** Score autom√°tico
- **Uso:** Ajusta manualmente el score de calidad

**Cu√°ndo ajustar:**
- Mejoraste mucho el output ‚Üí sube a 0.9-1.0
- Output sigue mediocre ‚Üí baja a 0.4-0.6
- Output es excelente ‚Üí 1.0

---

## üéØ Action Buttons (Review)

### **üíæ Save Changes**
- **Acci√≥n:** Guarda ediciones al ejemplo actual
- **Marca:** `edited: true` en metadata del ejemplo
- **No guarda:** Archivo (solo en memoria hasta "Save Dataset")

---

### **üö© Flag as Bad**
- **Acci√≥n:** Marca ejemplo como mala calidad
- **Marca:** `flagged: true`
- **Visual:** Status cambia a "üö© Flagged as bad"
- **Uso:** Marca para eliminar despu√©s

---

### **‚úÖ Mark as Good**
- **Acci√≥n:** Quita flag de ejemplo
- **Marca:** `flagged: false`
- **Visual:** Status cambia a "‚úÖ Good"

---

### **üóëÔ∏è Delete**
- **Acci√≥n:** Elimina ejemplo actual del dataset
- **Permanente:** S√≠ (en memoria, hasta guardar)
- **Navegaci√≥n:** Salta al siguiente ejemplo autom√°ticamente

---

### **üóëÔ∏è Remove All Flagged**
- **Acci√≥n:** Elimina TODOS los ejemplos con `flagged: true`
- **Batch operation:** S√≠
- **Confirmaci√≥n:** No (cuidado!)

**Ejemplo:**
```
Dataset original: 50 ejemplos
Flagged: 8 ejemplos (malos)
‚Üí Click "Remove All Flagged"
‚Üí Dataset nuevo: 42 ejemplos
Status: ‚úÖ Removed 8 flagged examples (42 remaining)
```

---

### **Save As (Dataset Name)**
- **Tipo:** Text input
- **Default:** `reviewed_dataset`
- **Uso:** Nombre para guardar dataset modificado

---

### **üíæ Save Dataset**
- **Acci√≥n:** Guarda dataset modificado a archivo
- **Metadata adicional:**
  ```json
  {
    "reviewed": true,
    "total_examples": 42,
    "edited_examples": 5
  }
  ```

---

# Tab 3: Training Manager

## üíª Hardware Info

### **GPU Info Display**
- **Tipo:** Markdown (read-only)
- **Contenido:**
  - Nombre de GPU (ej: NVIDIA GeForce RTX 4060 Ti)
  - Memoria total (GB)
  - Memoria allocated (GB)
  - Memoria free (GB)
  - Recomendaciones espec√≠ficas para tu GPU

**Ejemplo:**
```
‚úÖ GPU Available: NVIDIA GeForce RTX 4060 Ti

Memory:
- Total: 8.0 GB
- Allocated: 1.5 GB
- Free: 6.5 GB

Recommendation for RTX 4060 Ti (8GB):
- Batch size: 2-4
- Gradient accumulation: 4-8
- Use QLoRA (4-bit quantization)
```

**Si NO hay GPU:**
```
‚ùå No GPU detected - Training will use CPU (very slow)
```

---

## ‚öôÔ∏è Training Configuration

### **Training Dataset**
- **Tipo:** Dropdown
- **Valores:** Todos los datasets en `storage/datasets/`
- **Uso:** Selecciona dataset para entrenar

**Recomendaci√≥n:**
- Usa datasets "final" o "reviewed"
- M√≠nimo 30-50 ejemplos para entrenamiento efectivo
- Idealmente 100-200+ ejemplos

---

### **Model Name**
- **Tipo:** Text input
- **Default:** `ki_agent_v1`
- **Uso:** Nombre del modelo a entrenar

**Convenciones:**
```
ssrf_agent_v1       ‚Üí Primer modelo SSRF
ssrf_agent_v2       ‚Üí Segunda versi√≥n (m√°s entrenamiento)
xss_specialist      ‚Üí Especialista en XSS
general_bounty_v1   ‚Üí Modelo general de bug bounty
```

**Guardado en:**
```
storage/models/agents/{model_name}/
  ‚îú‚îÄ‚îÄ adapter_config.json
  ‚îú‚îÄ‚îÄ adapter_model.bin
  ‚îú‚îÄ‚îÄ training_config.json
  ‚îî‚îÄ‚îÄ training_log.txt
```

---

### **Epochs**
- **Tipo:** Slider
- **Rango:** 1 - 10
- **Default:** 3
- **Paso:** 1

**Qu√© es:**
- Una "epoch" = pasada completa por todo el dataset
- M√°s epochs = m√°s entrenamiento

**Recomendaciones:**
- **Datasets peque√±os (< 50 ejemplos):** 5-7 epochs
- **Datasets medianos (50-150 ejemplos):** 3-5 epochs
- **Datasets grandes (> 150 ejemplos):** 2-3 epochs

**Riesgos:**
- **Muy pocos epochs:** Modelo no aprende bien (underfitting)
- **Demasiados epochs:** Modelo memoriza (overfitting)

**Ejemplo:**
```
Dataset: 100 ejemplos
Epochs: 3
‚Üí Modelo ver√° cada ejemplo 3 veces
‚Üí Total de pasos de entrenamiento: 300
```

---

### **Batch Size**
- **Tipo:** Slider
- **Rango:** 1 - 8
- **Default:** 2
- **Paso:** 1

**Qu√© es:**
- N√∫mero de ejemplos procesados juntos en cada paso
- M√°s grande = m√°s r√°pido, pero m√°s memoria GPU

**Recomendaciones por GPU:**
```
RTX 4060 Ti (8GB):   batch_size = 2-4
RTX 3090 (24GB):     batch_size = 8-16
RTX 4090 (24GB):     batch_size = 8-16
CPU:                 batch_size = 1
```

**Trade-offs:**
- **Batch peque√±o (1-2):**
  - ‚úÖ Menos memoria
  - ‚úÖ M√°s actualizaciones de gradiente
  - ‚ùå Entrenamiento m√°s lento
- **Batch grande (4-8):**
  - ‚úÖ Entrenamiento m√°s r√°pido
  - ‚ùå M√°s memoria GPU
  - ‚ùå Menos actualizaciones de gradiente

**Ejemplo:**
```
Batch size: 2
GPU memory: ~4 GB usados
‚Üí Cada paso procesa 2 ejemplos simult√°neos
```

---

### **Learning Rate**
- **Tipo:** Number input
- **Default:** `2e-4` (0.0002)
- **Rango t√≠pico:** 1e-5 a 5e-4

**Qu√© es:**
- Qu√© tan r√°pido el modelo aprende
- Valor muy sensible

**Recomendaciones:**
```
LoRA/QLoRA fine-tuning:  1e-4 a 3e-4
Full fine-tuning:        1e-5 a 5e-5
Experimentos:            5e-4 (puede ser inestable)
```

**Riesgos:**
- **Learning rate muy alto (> 5e-4):**
  - Loss diverge (se va a infinito)
  - Entrenamiento falla
- **Learning rate muy bajo (< 1e-5):**
  - Entrenamiento extremadamente lento
  - Puede no converger en epochs razonables

**Formato de notaci√≥n cient√≠fica:**
```
2e-4 = 0.0002
1e-4 = 0.0001
5e-5 = 0.00005
```

---

### **LoRA r**
- **Tipo:** Slider
- **Rango:** 4 - 64
- **Default:** 16
- **Paso:** 4

**Qu√© es:**
- Rank de las matrices LoRA
- Controla cu√°ntos par√°metros se entrenan
- M√°s alto = m√°s capacidad de aprendizaje

**Recomendaciones:**
```
Tareas simples:          r = 8
Tareas est√°ndar:         r = 16
Tareas complejas:        r = 32
M√°xima capacidad:        r = 64
```

**Trade-offs:**
- **r bajo (4-8):**
  - ‚úÖ Muy r√°pido
  - ‚úÖ Poca memoria
  - ‚ùå Capacidad limitada
- **r alto (32-64):**
  - ‚úÖ Mayor capacidad
  - ‚ùå M√°s lento
  - ‚ùå M√°s memoria

**Ejemplo:**
```
LoRA r = 16
‚Üí ~1M par√°metros entrenables
‚Üí Modelo base: 8B par√°metros (frozen)
‚Üí Ratio: 0.0125% del modelo original
```

---

### **LoRA alpha**
- **Tipo:** Slider
- **Rango:** 8 - 128
- **Default:** 32
- **Paso:** 8

**Qu√© es:**
- Factor de escala para LoRA
- Controla qu√© tan fuerte es la adaptaci√≥n

**Regla general:**
```
LoRA alpha = 2 √ó LoRA r
```

**Ejemplos:**
```
r = 8   ‚Üí  alpha = 16
r = 16  ‚Üí  alpha = 32
r = 32  ‚Üí  alpha = 64
```

**No te preocupes demasiado:**
- Este par√°metro es menos cr√≠tico
- El default (2x de r) funciona bien en la mayor√≠a de casos

---

## üìä Training Estimates

### **üîç Estimate Training Time Button**
- **Acci√≥n:** Calcula tiempo estimado de entrenamiento
- **Basado en:**
  - N√∫mero de ejemplos en dataset
  - Epochs configurados
  - Batch size configurado
  - GPU disponible (o CPU)

**Output ejemplo:**
```
üìä Training Estimates:

- Dataset: ssrf_final.json
- Examples: 100
- Epochs: 3
- Batch size: 2
- Total batches: 150

‚è±Ô∏è Estimated Time:
- 75.0 minutes
- 1.25 hours

Note: Actual time may vary based on GPU load and model size.
```

**F√≥rmulas:**
```python
batches_per_epoch = num_examples // batch_size
total_batches = batches_per_epoch * epochs

# RTX 4060 Ti estimates:
seconds_per_batch = 2.0  # GPU
# or
seconds_per_batch = 10.0  # CPU

total_seconds = total_batches * seconds_per_batch
estimated_hours = total_seconds / 3600
```

---

## üöÄ Training Controls

### **üöÄ Start Training**
- **Acci√≥n:** Inicia entrenamiento
- **Requiere:**
  - Dataset seleccionado
  - Model name proporcionado
- **Proceso:**
  1. Prepara dataset (convierte a formato Alpaca)
  2. Configura LoRA
  3. Detecta GPU
  4. Inicia entrenamiento
  5. Muestra progress en tiempo real
  6. Guarda modelo al completar

**Training Output:**
```
‚úÖ Training Completed!

Model saved to: `storage/models/agents/ssrf_agent_v1`

Configuration:
- Base model: meta-llama/Llama-3.1-8B
- Epochs: 3
- Batch size: 2
- Learning rate: 0.0002
- LoRA r: 16
- LoRA alpha: 32

GPU: NVIDIA GeForce RTX 4060 Ti

Note: This is a simulation. Install transformers + peft for real training.
```

---

### **‚èπÔ∏è Stop Training**
- **Acci√≥n:** Detiene entrenamiento en progreso
- **Guardado:** √öltimo checkpoint guardado
- **Uso:** Si necesitas detener entrenamiento urgentemente

---

## üì¶ Trained Models

### **üîÑ Refresh List**
- **Acci√≥n:** Actualiza lista de modelos entrenados
- **Muestra:** Todos los modelos en `storage/models/agents/`

**Output ejemplo:**
```
ü§ñ Trained Models

üì¶ ssrf_agent_v1
- Base model: meta-llama/Llama-3.1-8B
- Created: 2025-10-02T20:30:00
- Path: `storage/models/agents/ssrf_agent_v1`

üì¶ xss_specialist
- Base model: meta-llama/Llama-3.1-8B
- Created: 2025-10-02T21:15:00
- Path: `storage/models/agents/xss_specialist`
```

---

# Tab 4: Testing System

## üìù Generate Test Cases

### **Category**
- **Tipo:** Dropdown
- **Valores:**
  - `SSRF`
  - `XSS`
  - `SQLi`
  - `IDOR`
  - `RCE`
  - `XXE`
  - `CSRF`
- **Default:** `SSRF`
- **Uso:** Tipo de vulnerabilidad para test cases

**Qu√© hace:**
- Selecciona templates predefinidos de test cases
- Genera prompts espec√≠ficos para esa vulnerabilidad

---

### **Number of Test Cases**
- **Tipo:** Slider
- **Rango:** 1 - 20
- **Default:** 5
- **Paso:** 1
- **Uso:** Cu√°ntos test cases generar

**Recomendaciones:**
- **Quick test:** 3-5 casos
- **Evaluaci√≥n est√°ndar:** 10 casos
- **Evaluaci√≥n completa:** 15-20 casos

---

### **üé≤ Generate Cases Button**
- **Acci√≥n:** Genera test cases para evaluaci√≥n
- **Output:** Tabla con test cases generados

**Ejemplo:**
```
Test Cases:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ID           ‚îÇ Instruction                            ‚îÇ Input                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ test_SSRF_1  ‚îÇ Explain SSRF in cloud environments    ‚îÇ AWS Lambda with HTTP requests   ‚îÇ
‚îÇ test_SSRF_2  ‚îÇ Describe mitigation for SSRF          ‚îÇ API allows user-provided URLs   ‚îÇ
‚îÇ test_SSRF_3  ‚îÇ What are risks of SSRF in microser... ‚îÇ Service mesh with internal APIs ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Status: ‚úÖ Generated 5 test cases for SSRF
```

---

## üîç Run Single Test

### **Test Case Index**
- **Tipo:** Slider
- **Rango:** 0 - (num_cases - 1)
- **Default:** 0
- **Uso:** Selecciona qu√© test case ejecutar

---

### **Model to Test**
- **Tipo:** Dropdown
- **Valores:**
  - `llama3.1 (base)` - Modelo base sin entrenar
  - Todos los modelos entrenados en `storage/models/agents/`
- **Uso:** Selecciona modelo a testear

---

### **‚ñ∂Ô∏è Run Test**
- **Acci√≥n:** Ejecuta un test case en un modelo
- **Output:** Resultado detallado del test

**Ejemplo:**
```
## Test Result: test_SSRF_1

**Category:** SSRF

**Instruction:** Explain how to identify SSRF vulnerabilities in cloud environments

**Input:** I'm testing an AWS Lambda function that makes HTTP requests

---

**Output:**

SSRF (Server-Side Request Forgery) en AWS Lambda es particularmente peligroso porque...
[Respuesta generada de 300+ palabras explicando SSRF en Lambda]

---

**Analysis:**
- Length: 1,234 characters
- Word count: 187
- Topics mentioned: 4/5
- Quality score: 87%
```

---

## üìä Compare Models

### **Model A (Base)**
- **Tipo:** Dropdown
- **Default:** `llama3.1 (base)`
- **Valores:** Base + modelos entrenados
- **Uso:** Primer modelo a comparar (t√≠picamente el base)

---

### **Model B (Fine-tuned)**
- **Tipo:** Dropdown
- **Valores:** Base + modelos entrenados
- **Uso:** Segundo modelo a comparar (t√≠picamente el fine-tuned)

---

### **üî¨ Compare Models Button**
- **Acci√≥n:** Ejecuta TODOS los test cases en ambos modelos
- **Proceso:**
  1. Ejecuta cada test case en Model A
  2. Ejecuta cada test case en Model B
  3. Calcula m√©tricas agregadas
  4. Compara resultados
  5. Determina ganador
  6. Guarda comparaci√≥n

**Output:**
```
# üß™ Model Comparison Report

## Model A: llama3.1 (base)

### Metrics:
- Average Quality Score: 62%
- Average Word Count: 145
- Total Tests: 5

## Model B: ssrf_agent_v1

### Metrics:
- Average Quality Score: 84%
- Average Word Count: 203
- Total Tests: 5

## üìä Comparison

‚úÖ Model B is +35.5% better in quality score
```

**Detailed Results:**
```
## Detailed Results

### llama3.1 (base) Results:

**Test test_SSRF_1:**
- Quality: 58%
- Output: SSRF is a vulnerability where...

**Test test_SSRF_2:**
- Quality: 65%
- Output: To mitigate SSRF, you should...

### ssrf_agent_v1 Results:

**Test test_SSRF_1:**
- Quality: 87%
- Output: SSRF (Server-Side Request Forgery) en entornos cloud como AWS Lambda permite...

**Test test_SSRF_2:**
- Quality: 89%
- Output: Las estrategias de mitigaci√≥n para SSRF incluyen...
```

---

## üìö Past Comparisons

### **üîÑ Refresh List**
- **Acci√≥n:** Actualiza lista de comparaciones guardadas
- **Muestra:** √öltimas 10 comparaciones

**Output:**
```
üìã Past Comparisons

### comparison_20251002_203045.json
- Timestamp: 2025-10-02T20:30:45
- Model A: llama3.1 (base)
- Model B: ssrf_agent_v1
- Path: `storage/test_results/comparison_20251002_203045.json`

### comparison_20251002_211530.json
- Timestamp: 2025-10-02T21:15:30
- Model A: llama3.1 (base)
- Model B: xss_specialist
- Path: `storage/test_results/comparison_20251002_211530.json`
```

---

# Tab 5: Settings

## System Settings

### **Storage Path**
- **Tipo:** Text (read-only)
- **Valor:** `storage/`
- **Muestra:** D√≥nde se guardan datasets, modelos, logs

---

### **Ollama Host**
- **Tipo:** Text (editable)
- **Default:** `http://localhost:11434`
- **Uso:** URL del servidor Ollama

**Cu√°ndo cambiar:**
- Ollama en otra m√°quina: `http://192.168.1.100:11434`
- Ollama en puerto diferente: `http://localhost:8080`

---

### **Ollama Model**
- **Tipo:** Text (editable)
- **Default:** `llama3.1`
- **Valores comunes:**
  - `llama3.1` - Llama 3.1 8B
  - `llama3.1:70b` - Llama 3.1 70B
  - `mistral` - Mistral 7B
  - `codellama` - Code Llama

---

### **GPU Settings**

#### **Device**
- **Valores:** `cuda` (GPU) / `cpu`
- **Auto-detect:** S√≠

#### **VRAM (GB)**
- **Muestra:** Memoria GPU detectada
- **Read-only:** S√≠

#### **Batch Size**
- **Default:** 2 (RTX 4060 Ti)
- **Ajustable:** S√≠

#### **Gradient Accumulation Steps**
- **Default:** 8
- **Qu√© hace:** Acumula gradientes para simular batch size m√°s grande
- **Effective batch size:** `batch_size √ó gradient_accumulation_steps`

**Ejemplo:**
```
batch_size = 2
gradient_accumulation = 8
‚Üí Effective batch size = 16
‚Üí Usa solo 2GB VRAM, pero aprende como si fuera batch de 16
```

---

# CLI Tool: dataset_cli.py

## Command: list

```bash
python tools/dataset_cli.py list
```

**Par√°metros:** Ninguno

**Output:**
```
üìö Available Datasets:
================================================================

üìÅ ssrf_v1.json
   Category: SSRF
   Examples: 50
   Created: 2025-10-02T17:30:00
   Path: /path/to/ssrf_v1.json

üìÅ xss_writeups.json
   Category: XSS
   Examples: 35
   Created: 2025-10-02T18:15:00
   Path: /path/to/xss_writeups.json

================================================================
Total: 2 datasets
```

---

## Command: merge

```bash
python tools/dataset_cli.py merge <datasets...> -o <output> [--no-dedupe]
```

**Par√°metros:**

### `datasets` (required, multiple)
- **Tipo:** Paths a archivos JSON
- **Ejemplo:** `ssrf_v1.json ssrf_v2.json ssrf_v3.json`

### `-o, --output` (required)
- **Tipo:** String
- **Uso:** Nombre del dataset mergeado
- **Ejemplo:** `-o ssrf_merged`

### `--no-dedupe` (optional)
- **Tipo:** Flag
- **Default:** Deduplicaci√≥n activada
- **Uso:** Deshabilita deduplicaci√≥n autom√°tica

**Ejemplo:**
```bash
python tools/dataset_cli.py merge \
  ssrf_v1.json \
  ssrf_v2.json \
  ssrf_v3.json \
  -o ssrf_complete
```

**Output:**
```
üîÑ Merging 3 datasets...
[INFO] Loaded 50 examples from ssrf_v1.json
[INFO] Loaded 30 examples from ssrf_v2.json
[INFO] Loaded 25 examples from ssrf_v3.json
[INFO] Total examples before merge: 105
[INFO] After deduplication: 95 examples

‚úÖ Merged dataset saved: storage/datasets/ssrf_complete.json
   Total examples: 95
   Duplicates removed: 10
```

---

## Command: dedupe

```bash
python tools/dataset_cli.py dedupe <dataset> -o <output> [-t <threshold>]
```

**Par√°metros:**

### `dataset` (required)
- **Tipo:** Path a archivo JSON
- **Ejemplo:** `ssrf_v1.json`

### `-o, --output` (required)
- **Tipo:** String
- **Ejemplo:** `-o ssrf_clean`

### `-t, --threshold` (optional)
- **Tipo:** Float (0.0 - 1.0)
- **Default:** 0.85
- **Uso:** Threshold de similitud para considerar duplicados
- **Ejemplo:** `-t 0.90` (m√°s estricto)

**Ejemplo:**
```bash
python tools/dataset_cli.py dedupe ssrf_v1.json -o ssrf_clean -t 0.90
```

**Output:**
```
üîç Deduplicating dataset: ssrf_v1.json

‚úÖ Deduplicated dataset saved: storage/datasets/ssrf_clean.json
   Original: 50 examples
   After deduplication: 45 examples
   Removed: 5 duplicates
```

---

## Command: validate

```bash
python tools/dataset_cli.py validate <dataset>
```

**Par√°metros:**

### `dataset` (required)
- **Tipo:** Path a archivo JSON
- **Ejemplo:** `ssrf_v1.json`

**Ejemplo:**
```bash
python tools/dataset_cli.py validate ssrf_final.json
```

**Output:**
```
‚úì Validating dataset: ssrf_final.json

üìä Validation Report:
================================================================

‚úÖ Dataset is VALID

Statistics:
  ‚Ä¢ total_examples: 95
  ‚Ä¢ missing_fields: 0
  ‚Ä¢ short_outputs: 2
  ‚Ä¢ low_quality: 3

‚ö†Ô∏è  Warnings (5):
  ‚Ä¢ Example 15: Output too short (45 chars)
  ‚Ä¢ Example 23: Output too short (38 chars)
  ‚Ä¢ Example 47: Low quality score (0.45)
  ‚Ä¢ Example 58: Low quality score (0.48)
  ‚Ä¢ Example 72: Low quality score (0.49)

================================================================
```

---

## Command: filter

```bash
python tools/dataset_cli.py filter <dataset> --min-quality <score> -o <output>
```

**Par√°metros:**

### `dataset` (required)
- **Tipo:** Path a archivo JSON

### `--min-quality` (optional)
- **Tipo:** Float (0.0 - 1.0)
- **Default:** 0.6
- **Uso:** Umbral m√≠nimo de quality score
- **Ejemplo:** `--min-quality 0.75`

### `-o, --output` (required)
- **Tipo:** String

**Ejemplo:**
```bash
python tools/dataset_cli.py filter ssrf_merged.json \
  --min-quality 0.75 \
  -o ssrf_high_quality
```

**Output:**
```
üîç Filtering dataset by quality (min: 0.75)

‚úÖ Filtered dataset saved: storage/datasets/ssrf_high_quality.json
   Original: 95 examples
   After filtering: 78 examples
   Filtered out: 17 examples
```

---

# Archivos de Configuraci√≥n

## backend/utils/config.py

### Settings class

```python
class Settings(BaseSettings):
    # Project
    project_root: Path = Path(__file__).parent.parent.parent
    storage_path: Optional[Path] = None  # Auto: project_root/storage
    datasets_path: Optional[Path] = None  # Auto: storage/datasets
    models_path: Optional[Path] = None    # Auto: storage/models

    # Ollama
    ollama_host: str = "http://localhost:11434"
    ollama_model: str = "llama3.1"
    ollama_timeout: int = 300  # seconds

    # Hardware
    device: str = "cuda"  # or "cpu"
    vram_gb: float = 8.0  # GPU memory

    # Training
    class TrainingConfig:
        batch_size: int = 2
        gradient_accumulation_steps: int = 8
        learning_rate: float = 2e-4
        num_epochs: int = 3
        warmup_steps: int = 100
        save_steps: int = 500
        logging_steps: int = 10
```

**C√≥mo modificar:**
```python
# Crear archivo .env en project root
OLLAMA_HOST=http://192.168.1.100:11434
OLLAMA_MODEL=mistral
DEVICE=cpu
```

---

# Resumen de Todos los Par√°metros

## Par√°metros Cr√≠ticos (Afectan Calidad)

| Par√°metro | Ubicaci√≥n | Impacto | Recomendaci√≥n |
|-----------|-----------|---------|---------------|
| **Examples per Document** | Dataset Manager | Alto | 5-10 |
| **Quality Threshold** | Dataset Manager | Alto | High (0.7) |
| **Epochs** | Training Manager | Muy Alto | 3-5 |
| **Learning Rate** | Training Manager | Muy Alto | 2e-4 |
| **LoRA r** | Training Manager | Alto | 16-32 |
| **Batch Size** | Training Manager | Medio | 2-4 (8GB GPU) |

## Par√°metros de Organizaci√≥n

| Par√°metro | Ubicaci√≥n | Impacto | Recomendaci√≥n |
|-----------|-----------|---------|---------------|
| **Category** | Dataset Manager | Bajo | Seg√∫n docs |
| **Dataset Name** | Dataset Manager | Bajo | Descriptivo |
| **Model Name** | Training Manager | Bajo | Versionado |

## Par√°metros T√©cnicos (Avanzados)

| Par√°metro | Ubicaci√≥n | Impacto | Recomendaci√≥n |
|-----------|-----------|---------|---------------|
| **LoRA alpha** | Training Manager | Bajo | 2 √ó LoRA r |
| **Gradient Accumulation** | Settings | Medio | 4-8 |
| **Similarity Threshold** | CLI dedupe | Medio | 0.85 |
| **Min Quality (filter)** | CLI filter | Alto | 0.7-0.75 |

---

# Glosario de T√©rminos

- **Epoch:** Pasada completa por todo el dataset
- **Batch Size:** Ejemplos procesados simult√°neamente
- **Learning Rate:** Velocidad de aprendizaje
- **LoRA:** Low-Rank Adaptation (fine-tuning eficiente)
- **QLoRA:** Quantized LoRA (usa menos memoria)
- **Quality Score:** M√©trica de calidad autom√°tica (0.0-1.0)
- **Gradient Accumulation:** T√©cnica para simular batch m√°s grande
- **Fine-tuning:** Entrenamiento especializado de un modelo
- **Inference:** Uso del modelo para generar predicciones
- **Token:** Unidad b√°sica de texto (palabra o subpalabra)
- **VRAM:** Memoria de GPU
- **Adapter:** Par√°metros LoRA entrenados

---

**Versi√≥n:** v0.3.0
**Fecha:** 2025-10-02
**Autor:** KI Platform Team
