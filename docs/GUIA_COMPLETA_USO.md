# ðŸ“– KI Platform - GuÃ­a Completa de Uso

## ðŸŽ¯ ExplicaciÃ³n de ParÃ¡metros de la Interfaz

### Tab 1: ðŸ“ Dataset Manager

#### SecciÃ³n: "Upload Documents"
**Drag & Drop Documents or Click to Browse**
- **QuÃ© hace:** Ãrea para arrastrar/soltar archivos o seleccionarlos
- **Formatos aceptados:** PDF, DOCX, TXT, Markdown (.md)
- **DÃ³nde se guardan:** Los archivos NO se copian automÃ¡ticamente
  - Gradio lee desde su ubicaciÃ³n original temporalmente
  - Si quieres mantenerlos, guÃ¡rdalos manualmente en: `/mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/documents/[categorÃ­a]/`

**Uploaded Files (tabla)**
- **Name:** Nombre del archivo subido
- **Size:** TamaÃ±o en KB
- **Type:** ExtensiÃ³n del archivo (PDF, DOCX, etc.)
- **Status:** âœ… Supported o âŒ Unsupported

---

#### SecciÃ³n: "Dataset Configuration"

**1. Vulnerability Category**
```
Opciones: SSRF, XSS, SQLi, IDOR, RCE, XXE, CSRF, LFI/RFI, Authentication Bypass, Custom
```
- **QuÃ© hace:** Define la categorÃ­a de vulnerabilidad para el dataset
- **Por quÃ© importa:** Los ejemplos generados se etiquetan con esta categorÃ­a
- **DÃ³nde se usa:** En metadata del dataset y para organizar ejemplos
- **Valor por defecto:** SSRF

**2. Examples per Document**
```
Rango: 1-20
Valor por defecto: 5
```
- **QuÃ© hace:** NÃºmero de ejemplos de entrenamiento a generar POR CADA documento
- **Ejemplo:** Si subes 10 documentos y pones 5 ejemplos â†’ 50 ejemplos totales
- **Recomendaciones:**
  - 3-5 para documentos largos (>5000 palabras)
  - 5-10 para documentos medianos (1000-5000 palabras)
  - 10-15 para documentos cortos (<1000 palabras)

**3. Quality Threshold**
```
Opciones: High, Medium, Low
```
- **High:** Solo acepta ejemplos de alta calidad (filtrado estricto)
  - MÃ¡s lento, menos ejemplos, mejor calidad
- **Medium:** Balance entre calidad y cantidad
  - Velocidad media, calidad aceptable
- **Low:** Acepta todos los ejemplos
  - RÃ¡pido, mayor cantidad, calidad variable

**4. Dataset Name**
```
Valor por defecto: "my_dataset"
```
- **QuÃ© hace:** Nombre del archivo JSON que se guardarÃ¡
- **DÃ³nde se guarda:** `/storage/datasets/[nombre].json`
- **Formato:** Se limpia automÃ¡ticamente (solo alfanumÃ©ricos, -, _)

---

#### SecciÃ³n: "Processing Results"

**Parsing Results (tabla)**
- **File:** Nombre del documento parseado
- **Type:** Tipo de archivo (PDF, DOCX, TEXT, MARKDOWN)
- **Words:** Cantidad de palabras extraÃ­das
- **Status:** âœ… Success o âŒ Error con mensaje

**Generation Log**
- **QuÃ© muestra:** Log en tiempo real de la generaciÃ³n
- **InformaciÃ³n incluida:**
  - [INFO] Archivos procesados
  - [SUCCESS] Ejemplos generados
  - [WARNING] Problemas de calidad
  - [ERROR] Errores durante generaciÃ³n

**Status**
- Mensaje final con resumen: "âœ… Generated X examples from Y documents"

---

### Tab 2: ðŸŽ“ Training Studio (Preparado para SesiÃ³n 4)

**Select Dataset**
- Dropdown con datasets guardados en `/storage/datasets/`

**Base Model**
```
Opciones: llama-3.1-8b, mistral-7b, phi-3-mini
```
- Modelo base de HuggingFace para fine-tuning

**Hardware Preset**
```
Opciones: RTX 4060 Ti (8GB), RTX 3080 (10GB), RTX 4090 (24GB), Custom
```
- **RTX 4060 Ti (8GB):** ConfiguraciÃ³n actual optimizada
  - batch_size: 2
  - gradient_accumulation: 8
  - 4-bit quantization: Enabled
  - max_vram_usage: 7.5GB

**Training Epochs**
```
Rango: 1-10
Valor por defecto: 3
```
- NÃºmero de veces que el modelo verÃ¡ el dataset completo

**Advanced Settings:**
- **Learning Rate:** 2e-4 (tasa de aprendizaje)
- **Batch Size:** 2 (muestras por paso)
- **Gradient Accumulation Steps:** 8 (acumular gradientes antes de actualizar)

---

### Tab 3: ðŸ§ª Testing Lab (Preparado para SesiÃ³n 4)

**Select Trained Model**
- Lista de modelos entrenados guardados en `/storage/models/agents/`

**Temperature**
```
Rango: 0.1 - 2.0
Valor por defecto: 0.7
```
- **0.1-0.5:** Respuestas mÃ¡s determinÃ­sticas y conservadoras
- **0.7-0.9:** Balance creatividad/precisiÃ³n (recomendado)
- **1.0-2.0:** Respuestas mÃ¡s creativas y variadas

**Test Input**
- Campo de texto para ingresar escenario de prueba

**Model Response**
- Salida del modelo entrenado

---

### Tab 4: âš™ï¸ Settings

**Ollama Host**
```
Valor por defecto: http://localhost:11434
```
- URL del servidor Ollama (local)

**Default Ollama Model**
```
Opciones: llama3.1, llama3.1:70b, mistral, mixtral, phi3
```
- Modelo LLM para generar datasets

**Max VRAM Usage (GB)**
```
Rango: 1.0 - 8.0
Valor por defecto: 7.5
```
- LÃ­mite de memoria GPU para entrenamiento
- Dejar 0.5GB libre para el sistema

**Use 4-bit Quantization**
```
Valor por defecto: True
```
- Reduce uso de VRAM en ~50%
- Permite entrenar modelos mÃ¡s grandes en GPUs pequeÃ±as

---

## ðŸ“‚ DÃ³nde se Almacenan los Archivos

### Estructura Completa de Storage:

```
/mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/
â”‚
â”œâ”€â”€ documents/                    â† DOCUMENTOS FUENTE
â”‚   â”œâ”€â”€ ssrf/                     â† Docs de SSRF
â”‚   â”œâ”€â”€ xss/                      â† Docs de XSS
â”‚   â”œâ”€â”€ sqli/                     â† Docs de SQLi
â”‚   â””â”€â”€ general/                  â† Docs generales
â”‚
â”œâ”€â”€ datasets/                     â† DATASETS GENERADOS
â”‚   â”œâ”€â”€ raw/                      â† Datasets sin procesar
â”‚   â”œâ”€â”€ processed/                â† Datasets validados
â”‚   â””â”€â”€ final/                    â† Datasets listos para entrenar
â”‚   â””â”€â”€ [nombre].json             â† Datasets guardados manualmente
â”‚
â”œâ”€â”€ models/                       â† MODELOS ENTRENADOS
â”‚   â”œâ”€â”€ base/                     â† Modelos base descargados
â”‚   â””â”€â”€ agents/                   â† Agentes entrenados (LoRA adapters)
â”‚       â””â”€â”€ ssrf_agent_v1/
â”‚       â””â”€â”€ xss_agent_v2/
â”‚
â”œâ”€â”€ logs/                         â† LOGS DEL SISTEMA
â”‚   â”œâ”€â”€ training/                 â† Logs de entrenamiento
â”‚   â”œâ”€â”€ generation/               â† Logs de generaciÃ³n de datasets
â”‚   â””â”€â”€ system/                   â† Logs generales
â”‚
â””â”€â”€ databases/                    â† BASES DE DATOS
    â”œâ”€â”€ metadata.db               â† SQLite con metadata
    â””â”€â”€ chromadb/                 â† Vector DB para embeddings
```

### Detalles de Ubicaciones:

#### 1. **Documentos Cargados:**
**TEMPORAL:** Cuando subes archivos con drag & drop:
- Gradio crea copias temporales en `/tmp/gradio/`
- Estos archivos se borran al cerrar la aplicaciÃ³n

**PERMANENTE (Recomendado):** Para mantener documentos:
```bash
# Copiar manualmente a:
/mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/documents/[categoria]/

# Ejemplo:
cp mi_documento.pdf /mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/documents/ssrf/
```

#### 2. **Datasets Generados:**
Cuando haces click en "Save Dataset", se guardan en:
```
/mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/datasets/

Archivo: [nombre_del_dataset].json
```

**Estructura del JSON:**
```json
{
  "metadata": {
    "category": "SSRF",
    "created_at": "2025-10-02T17:30:00",
    "total_examples": 50,
    "source_documents": 10,
    "examples_per_doc": 5,
    "quality_level": "High"
  },
  "examples": [
    {
      "instruction": "Explain SSRF vulnerability",
      "input": "What is SSRF in AWS?",
      "output": "SSRF (Server-Side Request Forgery)...",
      "source": "aws_ssrf_guide.pdf",
      "category": "SSRF",
      "timestamp": "2025-10-02T17:30:15"
    }
  ]
}
```

#### 3. **Modelos Entrenados:**
DespuÃ©s de entrenar (SesiÃ³n 4+), se guardan en:
```
/mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/models/agents/

Estructura:
ssrf_agent_v1/
â”œâ”€â”€ adapter_config.json
â”œâ”€â”€ adapter_model.bin
â”œâ”€â”€ training_args.bin
â””â”€â”€ tokenizer files
```

---

## ðŸ”„ Sistema de Datasets: Â¿Nuevo o Mejorar Existente?

### **Comportamiento Actual (v0.1.0):**

#### âŒ NO Hace (Por Ahora):
- No puede **mejorar/actualizar** un dataset existente automÃ¡ticamente
- No tiene funcionalidad de "merge" automÃ¡tico
- No detecta duplicados entre datasets

#### âœ… SÃ Hace:
- **Genera datasets NUEVOS** cada vez
- Cada generaciÃ³n es independiente
- Puedes guardar mÃºltiples versiones

### **SoluciÃ³n para Mejorar Datasets Existentes:**

#### OpciÃ³n 1: Merge Manual (PrÃ³xima SesiÃ³n 4)
```python
# Implementaremos una funciÃ³n de merge:
1. Cargar dataset existente
2. Generar nuevos ejemplos
3. Combinar y deduplicar
4. Guardar dataset mejorado
```

#### OpciÃ³n 2: Workflow Recomendado (Ahora)
```
1. Generar dataset inicial: "ssrf_v1.json" (50 ejemplos)
2. Generar dataset adicional: "ssrf_v2.json" (30 ejemplos nuevos)
3. En SesiÃ³n 4: Implementar merge â†’ "ssrf_final.json" (80 ejemplos sin duplicados)
```

---

## ðŸ”„ Sistema de Feedback para Mejora

### **Estado Actual (v0.1.0):**

#### âŒ NO Implementado (AÃºn):
- No hay sistema de feedback directo en la UI
- No puede marcar ejemplos como "buenos" o "malos"
- No hay re-entrenamiento automÃ¡tico con correcciones

### **Roadmap de Feedback (Sesiones Futuras):**

#### Fase 1: Review Manual (SesiÃ³n 4)
```
Dataset Manager â†’ Nueva secciÃ³n:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“ Review Generated Examples    â”‚
â”‚                                  â”‚
â”‚ Example 1/50                     â”‚
â”‚ Instruction: [...]               â”‚
â”‚ Input: [...]                     â”‚
â”‚ Output: [...]                    â”‚
â”‚                                  â”‚
â”‚ Quality: â­â­â­â­â­              â”‚
â”‚ [âœ“ Accept] [âœ— Reject] [âœï¸ Edit] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Fase 2: Feedback Loop (SesiÃ³n 5-6)
```python
# Sistema de feedback propuesto:
1. Testing Lab â†’ Usuario prueba modelo
2. Marca respuesta como "incorrecta"
3. Proporciona correcciÃ³n esperada
4. Sistema genera ejemplo correcto
5. Se aÃ±ade al dataset de fine-tuning
6. Re-entrena con ejemplos corregidos
```

#### Fase 3: Active Learning (Futuro)
```
1. Modelo identifica ejemplos difÃ­ciles
2. Pide feedback del usuario
3. Aprende de correcciones
4. Mejora iterativamente
```

---

## ðŸ’¡ CÃ³mo Implementar Feedback (Manual por Ahora)

### MÃ©todo 1: Editar Dataset JSON

**Paso 1:** Generar y guardar dataset
```bash
Dataset guardado en:
/storage/datasets/ssrf_v1.json
```

**Paso 2:** Abrir con editor de texto
```bash
nano /mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/datasets/ssrf_v1.json
```

**Paso 3:** Editar ejemplos incorrectos
```json
{
  "instruction": "Mal ejemplo - EDITAR",
  "output": "Respuesta incorrecta"
}

// Cambiar a:
{
  "instruction": "Ejemplo corregido",
  "output": "Respuesta correcta basada en feedback"
}
```

**Paso 4:** Guardar y usar en entrenamiento

### MÃ©todo 2: Script de CorrecciÃ³n (Crear en SesiÃ³n 4)

```python
# feedback_tool.py (a implementar)

def add_corrected_example(dataset_path, bad_example_id, corrected_output):
    """
    AÃ±ade ejemplo corregido al dataset
    """
    dataset = load_dataset(dataset_path)

    # Marcar ejemplo malo
    dataset['examples'][bad_example_id]['quality'] = 'rejected'

    # AÃ±adir correcciÃ³n
    corrected_example = {
        "instruction": dataset['examples'][bad_example_id]['instruction'],
        "input": dataset['examples'][bad_example_id]['input'],
        "output": corrected_output,
        "source": "user_feedback",
        "quality": "verified"
    }

    dataset['examples'].append(corrected_example)
    save_dataset(dataset, dataset_path)
```

---

## ðŸ“Š Resumen de Capacidades Actuales vs Futuras

| Funcionalidad | Estado Actual (v0.1.0) | PrÃ³xima ImplementaciÃ³n |
|---------------|------------------------|------------------------|
| **Upload documentos** | âœ… Funcional | - |
| **Parse documentos** | âœ… Funcional | - |
| **Generar datasets** | ðŸŸ¡ Simulado | SesiÃ³n 4: Ollama real |
| **Guardar datasets** | âœ… Funcional | - |
| **Merge datasets** | âŒ No | SesiÃ³n 4 |
| **Deduplicar ejemplos** | âŒ No | SesiÃ³n 4 |
| **Review manual** | âŒ No | SesiÃ³n 4 |
| **Feedback en UI** | âŒ No | SesiÃ³n 5 |
| **Re-entrenamiento con feedback** | âŒ No | SesiÃ³n 6 |
| **Active Learning** | âŒ No | Futuro |

---

## ðŸŽ¯ Workflow Recomendado (Ahora)

### Para Crear un Buen Dataset:

**1. Recopilar Documentos (Manual)**
```bash
# Crear carpeta por categorÃ­a
mkdir -p /mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki/storage/documents/ssrf

# Copiar tus PDFs/docs
cp ~/mis_documentos_ssrf/*.pdf ./storage/documents/ssrf/
```

**2. Generar Dataset en UI**
```
1. Upload documentos (drag & drop)
2. Click "Parse Documents"
3. Configurar:
   - Category: SSRF
   - Examples per doc: 5
   - Quality: High
4. Click "Generate Dataset"
5. Revisar logs
6. Click "Save Dataset" con nombre: "ssrf_initial"
```

**3. Revisar y Editar Manualmente**
```bash
# Abrir dataset
nano storage/datasets/ssrf_initial.json

# Revisar cada ejemplo
# Editar outputs incorrectos
# Eliminar ejemplos malos
```

**4. Generar Datasets Adicionales**
```
Repetir proceso con nuevos documentos
Guardar como: ssrf_batch2.json, ssrf_batch3.json, etc.
```

**5. Preparar para Entrenamiento (SesiÃ³n 4)**
```
Implementaremos merge tool para combinar:
ssrf_initial.json + ssrf_batch2.json â†’ ssrf_final.json
```

---

## ðŸ”§ Configuraciones Importantes

### Archivos de ConfiguraciÃ³n:

**1. `/backend/utils/config.py`**
- Todas las rutas y parÃ¡metros del sistema
- Puedes editar valores por defecto aquÃ­

**2. `.env` (crear si necesitas customizar)**
```bash
# Ejemplo .env
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1
MAX_VRAM_USAGE_GB=7.5
EXAMPLES_PER_DOCUMENT=5
QUALITY_THRESHOLD=0.7
```

---

**Â¿Necesitas que implemente alguna de estas funcionalidades ahora? Por ejemplo:**
1. Script para merge de datasets
2. Tool de review manual de ejemplos
3. Deduplicador de ejemplos
4. Validador de calidad personalizado

