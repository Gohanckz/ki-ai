# ğŸš€ KI Platform - Nuevas Funcionalidades Implementadas

## âœ… Implementado en Esta SesiÃ³n

### 1. ğŸ¤– GeneraciÃ³n Real con Ollama

**Â¿QuÃ© es?**
Ya no es simulaciÃ³n - ahora KI usa Ollama para generar ejemplos reales de entrenamiento usando IA.

**CÃ³mo funciona:**
1. Subes documentos sobre vulnerabilidades
2. KI analiza el contenido con Llama 3.1
3. Genera ejemplos educativos de alta calidad
4. Filtra por calidad automÃ¡ticamente

**Beneficios:**
- âœ… Ejemplos basados en contenido real de documentos
- âœ… Explicaciones tÃ©cnicas detalladas
- âœ… Diversidad en escenarios y contextos
- âœ… Quality scoring automÃ¡tico

**Estado:**
- ğŸŸ¢ **Ollama corriendo:** Genera ejemplos reales con IA
- ğŸŸ¡ **Ollama no disponible:** Usa generaciÃ³n simulada (fallback)

---

### 2. ğŸ”„ Merge de Datasets

**Â¿QuÃ© es?**
Combina mÃºltiples datasets en uno solo, eliminando duplicados automÃ¡ticamente.

**Casos de uso:**
```
Dataset 1: ssrf_v1.json (50 ejemplos de docs iniciales)
Dataset 2: ssrf_v2.json (30 ejemplos de nuevos docs)
Dataset 3: ssrf_v3.json (25 ejemplos corregidos)

â†’ Merge â†’ ssrf_final.json (95 ejemplos Ãºnicos)
```

**CÃ³mo usarlo:**

#### OpciÃ³n 1: CLI Tool
```bash
cd /mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki
source ../venv/bin/activate

# Merge mÃºltiples datasets
python tools/dataset_cli.py merge ssrf_v1.json ssrf_v2.json ssrf_v3.json -o ssrf_final

# Ver resultado
python tools/dataset_cli.py list
```

#### OpciÃ³n 2: Python
```python
from backend.core.dataset_tools import DatasetTools

tools = DatasetTools()

# Merge
merged = tools.merge_datasets(
    dataset_paths=[
        Path("storage/datasets/ssrf_v1.json"),
        Path("storage/datasets/ssrf_v2.json")
    ],
    output_name="ssrf_merged",
    deduplicate=True
)

# Save
tools.save_dataset(merged, "ssrf_final")
```

---

### 3. ğŸ§¹ DeduplicaciÃ³n Inteligente

**Â¿QuÃ© es?**
Elimina ejemplos duplicados o muy similares usando anÃ¡lisis de similitud.

**CÃ³mo funciona:**
- Calcula hash de contenido (duplicados exactos)
- Mide similitud semÃ¡ntica (duplicados parciales)
- Umbral configurable (default: 85% similitud)

**Ejemplo:**
```
Ejemplo 1: "Explica SSRF en AWS Lambda"
Ejemplo 2: "Describe SSRF en AWS Lambda"
â†’ Similitud: 92% â†’ DUPLICADO (se elimina uno)

Ejemplo 3: "SSRF en API Gateway"
â†’ Similitud: 45% â†’ ÃšNICO (se mantiene)
```

**CÃ³mo usarlo:**
```bash
# Deduplicar dataset
python tools/dataset_cli.py dedupe ssrf_v1.json -o ssrf_v1_clean

# Threshold personalizado
python tools/dataset_cli.py dedupe ssrf_v1.json -o ssrf_clean -t 0.90
```

---

### 4. âœ… Validador de Calidad

**Â¿QuÃ© valida?**
- âœ“ Estructura correcta del JSON
- âœ“ Campos requeridos presentes
- âœ“ Longitud mÃ­nima de outputs
- âœ“ Scores de calidad
- âœ“ Campos faltantes
- âœ“ Ejemplos mal formados

**Reporte incluye:**
- Total de ejemplos
- Ejemplos con errores
- Advertencias de calidad
- Recomendaciones

**CÃ³mo usarlo:**
```bash
# Validar dataset
python tools/dataset_cli.py validate ssrf_v1.json

# Output:
# âœ… Dataset is VALID
# Statistics:
#   â€¢ total_examples: 50
#   â€¢ missing_fields: 0
#   â€¢ short_outputs: 2
#   â€¢ low_quality: 1
```

---

### 5. ğŸ¯ Filtrado por Calidad

**Â¿QuÃ© es?**
Filtra ejemplos basÃ¡ndose en quality score automÃ¡tico.

**Quality Score (0.0 - 1.0):**
- **0.8-1.0:** Excelente calidad
- **0.6-0.8:** Buena calidad
- **0.4-0.6:** Calidad media
- **<0.4:** Baja calidad

**Factores que afectan el score:**
- Longitud y detalle del output
- Claridad de la instruction
- Contexto en el input
- Estructura completa

**CÃ³mo usarlo:**
```bash
# Filtrar solo alta calidad (>=0.7)
python tools/dataset_cli.py filter ssrf_v1.json --min-quality 0.7 -o ssrf_high_quality

# Resultado:
# Original: 50 ejemplos
# DespuÃ©s: 42 ejemplos
# Filtrados: 8 ejemplos de baja calidad
```

---

## ğŸ› ï¸ Herramienta CLI Completa

### InstalaciÃ³n:
```bash
cd /mnt/c/Users/Gohanckz/Desktop/IA-Proyect/ki
source ../venv/bin/activate
chmod +x tools/dataset_cli.py
```

### Comandos Disponibles:

#### 1. Listar Datasets
```bash
python tools/dataset_cli.py list

# Output:
# ğŸ“š Available Datasets:
# ================================================================
#
# ğŸ“ ssrf_v1.json
#    Category: SSRF
#    Examples: 50
#    Created: 2025-10-02T17:30:00
#    Path: /path/to/ssrf_v1.json
```

#### 2. Merge Datasets
```bash
# Merge 2+ datasets
python tools/dataset_cli.py merge ssrf_v1.json ssrf_v2.json -o ssrf_merged

# Merge sin deduplicar
python tools/dataset_cli.py merge dataset1.json dataset2.json -o merged --no-dedupe
```

#### 3. Deduplicar
```bash
# Deduplicar con threshold default (0.85)
python tools/dataset_cli.py dedupe ssrf_v1.json -o ssrf_clean

# Threshold personalizado (mÃ¡s estricto)
python tools/dataset_cli.py dedupe ssrf_v1.json -o ssrf_clean -t 0.95
```

#### 4. Validar
```bash
python tools/dataset_cli.py validate ssrf_v1.json
```

#### 5. Filtrar por Calidad
```bash
# Solo ejemplos con quality >= 0.7
python tools/dataset_cli.py filter ssrf_v1.json --min-quality 0.7 -o ssrf_hq

# Solo excelente calidad (>= 0.9)
python tools/dataset_cli.py filter ssrf_v1.json --min-quality 0.9 -o ssrf_excellent
```

---

## ğŸ“Š Workflow Completo Actualizado

### Paso 1: Generar Dataset Inicial
```
1. Abrir UI: http://localhost:7860
2. Upload documentos sobre SSRF
3. Parse Documents
4. Generate Dataset (Ollama generarÃ¡ ejemplos reales)
5. Save: "ssrf_v1"
```

### Paso 2: Generar Datasets Adicionales
```
1. Upload mÃ¡s documentos SSRF
2. Generate Dataset
3. Save: "ssrf_v2"

Repetir con diferentes docs â†’ ssrf_v3, ssrf_v4...
```

### Paso 3: Merge y Limpieza (CLI)
```bash
# Activar venv
source ../venv/bin/activate

# Merge todos
python tools/dataset_cli.py merge \
  ssrf_v1.json \
  ssrf_v2.json \
  ssrf_v3.json \
  -o ssrf_merged

# Resultado: ssrf_merged.json con ejemplos Ãºnicos
```

### Paso 4: Validar Calidad
```bash
# Validar
python tools/dataset_cli.py validate ssrf_merged.json

# Si hay ejemplos de baja calidad, filtrar
python tools/dataset_cli.py filter ssrf_merged.json --min-quality 0.7 -o ssrf_final
```

### Paso 5: Dataset Final
```
âœ… ssrf_final.json
   â€¢ Ejemplos Ãºnicos (sin duplicados)
   â€¢ Alta calidad (score >= 0.7)
   â€¢ Listo para entrenamiento
```

---

## ğŸ¯ Mejoras en la UI

### Dataset Manager - Cambios:

**Antes (v0.1.0):**
- âŒ GeneraciÃ³n simulada
- âŒ No mostraba estadÃ­sticas reales

**Ahora (v0.2.0):**
- âœ… GeneraciÃ³n real con Ollama
- âœ… EstadÃ­sticas detalladas:
  - Documentos procesados
  - Ejemplos generados
  - Ejemplos validados
  - Ejemplos rechazados por calidad
  - Tasa de rechazo
- âœ… DetecciÃ³n automÃ¡tica de Ollama
- âœ… Fallback a simulaciÃ³n si Ollama no disponible

**Log de GeneraciÃ³n Mejorado:**
```
[INFO] Starting dataset generation with Ollama
[INFO] Category: SSRF
[INFO] Target: 5 examples per document
[INFO] Quality level: High
[INFO] Total documents: 10

[âœ“] Ollama is running - using real AI generation

[SUCCESS] Dataset generation complete!

ğŸ“Š Statistics:
  â€¢ Documents processed: 10
  â€¢ Examples generated: 50
  â€¢ Examples validated: 45
  â€¢ Examples rejected: 5

[INFO] Quality rejection rate: 10.0%
```

---

## ğŸ”§ API de ProgramaciÃ³n

### DatasetGenerator
```python
from backend.core.dataset_generator import DatasetGenerator

generator = DatasetGenerator()

# Generar ejemplos de un documento
examples = generator.generate_examples_from_document(
    document_text="Contenido del documento...",
    document_name="ssrf_guide.pdf",
    category="SSRF",
    num_examples=5,
    quality_level="High",
    temperature=0.7
)

# Generar dataset completo
dataset = generator.generate_dataset(
    parsed_documents={
        "doc1.pdf": {"full_text": "...", "word_count": 1000},
        "doc2.pdf": {"full_text": "...", "word_count": 1500}
    },
    category="SSRF",
    examples_per_doc=5,
    quality_level="High"
)
```

### DatasetTools
```python
from backend.core.dataset_tools import DatasetTools

tools = DatasetTools()

# Merge
merged = tools.merge_datasets([path1, path2], "merged", deduplicate=True)

# Deduplicate
unique = tools.deduplicate_examples(examples, similarity_threshold=0.85)

# Validate
report = tools.validate_dataset(dataset)

# Filter
high_quality = tools.filter_examples_by_quality(examples, min_quality=0.7)

# Balance (limitar por categorÃ­a)
balanced = tools.balance_dataset(dataset, max_per_category=100)

# List
datasets = tools.list_datasets()

# Save
path = tools.save_dataset(dataset, "my_dataset")
```

---

## ğŸ“ˆ ComparaciÃ³n: Antes vs Ahora

| Funcionalidad | v0.1.0 (Antes) | v0.2.0 (Ahora) |
|---------------|----------------|----------------|
| **GeneraciÃ³n de datasets** | Simulada | âœ… Real con Ollama |
| **Quality scoring** | No | âœ… AutomÃ¡tico |
| **Merge datasets** | Manual (editar JSON) | âœ… CLI tool |
| **DeduplicaciÃ³n** | No | âœ… Inteligente |
| **ValidaciÃ³n** | No | âœ… Completa |
| **Filtrado por calidad** | No | âœ… CLI + API |
| **EstadÃ­sticas** | BÃ¡sicas | âœ… Detalladas |
| **Logs** | Simples | âœ… Informativos |

---

## ğŸ“ Ejemplos de Uso Real

### Caso 1: Dataset de SSRF desde mÃºltiples fuentes

```bash
# DÃ­a 1: Generar desde reportes de HackerOne
UI â†’ Upload reportes H1 â†’ Generate â†’ Save "ssrf_h1"

# DÃ­a 2: Generar desde writeups de bug bounty
UI â†’ Upload writeups â†’ Generate â†’ Save "ssrf_writeups"

# DÃ­a 3: Generar desde documentaciÃ³n tÃ©cnica
UI â†’ Upload docs AWS â†’ Generate â†’ Save "ssrf_aws_docs"

# DÃ­a 4: Merge y limpieza
python tools/dataset_cli.py merge \
  ssrf_h1.json \
  ssrf_writeups.json \
  ssrf_aws_docs.json \
  -o ssrf_complete

python tools/dataset_cli.py filter ssrf_complete.json \
  --min-quality 0.75 \
  -o ssrf_final

# Resultado: 150+ ejemplos Ãºnicos de alta calidad
```

### Caso 2: Mejorar dataset existente

```bash
# Tienes ssrf_old.json (100 ejemplos, algunos duplicados)

# 1. Deduplicar
python tools/dataset_cli.py dedupe ssrf_old.json -o ssrf_clean

# 2. Validar
python tools/dataset_cli.py validate ssrf_clean.json

# 3. Filtrar baja calidad
python tools/dataset_cli.py filter ssrf_clean.json \
  --min-quality 0.6 \
  -o ssrf_improved

# 4. Generar nuevos ejemplos en UI
UI â†’ Upload nuevos docs â†’ Generate â†’ Save "ssrf_new"

# 5. Merge
python tools/dataset_cli.py merge \
  ssrf_improved.json \
  ssrf_new.json \
  -o ssrf_v2_final
```

---

## ğŸš€ PrÃ³ximos Pasos (SesiÃ³n 5)

Con estas herramientas ya puedes:
1. âœ… Generar datasets reales con IA
2. âœ… Mergear mÃºltiples versiones
3. âœ… Eliminar duplicados
4. âœ… Validar calidad
5. âœ… Filtrar por calidad

**Siguiente fase:**
- ğŸ”œ UI para review/ediciÃ³n de ejemplos
- ğŸ”œ Feedback loop en interfaz
- ğŸ”œ Entrenamiento de modelos
- ğŸ”œ Testing de agentes entrenados

---

## ğŸ“š DocumentaciÃ³n Adicional

**GuÃ­as:**
- `GUIA_COMPLETA_USO.md` - GuÃ­a general de la plataforma
- `RESUMEN_RAPIDO.txt` - Resumen visual rÃ¡pido
- `NUEVAS_FEATURES.md` - Este archivo

**Archivos de cÃ³digo:**
- `backend/core/dataset_generator.py` - GeneraciÃ³n con Ollama
- `backend/core/dataset_tools.py` - Herramientas de gestiÃ³n
- `tools/dataset_cli.py` - CLI tool
- `frontend/components/dataset_manager.py` - UI actualizada

---

**VersiÃ³n:** v0.2.0
**Fecha:** 2025-10-02
**Estado:** âœ… Todas las features funcionando
